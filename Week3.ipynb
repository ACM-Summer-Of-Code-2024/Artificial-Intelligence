{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cbe65a",
   "metadata": {},
   "source": [
    "   \n",
    "<div style=\"background-image: linear-gradient(to left, rgb(255, 255, 255), rgb(138, 136, 136)); width: auto; margin: 10px;\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/f/fd/University_of_Tehran_logo.svg/225px-University_of_Tehran_logo.svg.png\" width=100px width=auto style=\"padding:10px; vertical-align: center;\">\n",
    "\n",
    "</div>\n",
    "   \n",
    "<div   style:\"text-align: center; background-image: linear-gradient(to left, rgb(255, 255, 255), rgb( 219, 204, 245  ));width: 400px; height: 30px; \">\n",
    "<h1 style=\"font-family: Georgia; color: black; text-align: center; \">SOC AI Course </h1>\n",
    "\n",
    "</div>\n",
    "    <div   style:\"border: 3px solid green;text-align: center; \">\n",
    "<h1 style=\"font-family: Georgia; color: black; text-align: center; \">Week3</h1>\n",
    "<h5 style=\"font-family: Georgia; color: black; text-align: center; \">Designer: Mohammad Amanlou, Marzieh Mousavi</h5>\n",
    "\n",
    "</div>\n",
    "\n",
    "   </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f27cc",
   "metadata": {},
   "source": [
    "## 1. Text Processing and Bayes' Theorem\n",
    "\n",
    "We begin by reviewing the theory of Bayes' Theorem.\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem allows us to calculate the probability of an event based on prior knowledge of conditions related to the event. In other words, it helps us update our belief about the occurrence of an event given new evidence.\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$[ P(c|x) = \\frac{P(x|c)P(c)}{P(x)} ]$\n",
    "\n",
    "Where:\n",
    "- $( P(c|x) $) is the posterior probability: the probability of class $( c )$ given the data $( x )$.\n",
    "- $( P(x|c) $) is the likelihood: the probability of the data $( x )$ given that the event belongs to class $( c )$.\n",
    "- $( P(c) )$ is the prior probability: the initial probability of class $( c )$ before seeing the data.\n",
    "- $( P(x) )$ is the evidence: the total probability of the data $( x )$.\n",
    "\n",
    "Using Bayes' Theorem, we can estimate the probability of an event occurring based on prior knowledge and new evidence.\n",
    "\n",
    "### Example of Bayes' Theorem\n",
    "\n",
    "Consider an example with 100 healthy individuals and 100 COVID-19 patients. The test results are as follows:\n",
    "\n",
    "|  | COVID Positive | COVID Negative |\n",
    "|--|--|--|\n",
    "| Healthy | 10 | 90 |\n",
    "| Infected | 95 | 5 |\n",
    "\n",
    "Assume 60% of the population is infected. What is the probability that a person who tested positive is actually healthy?\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "1. **Prior Probability**:\n",
    "    - $( P(\\text{Healthy}) = 40\\% )$\n",
    "    - $( P(\\text{Infected}) = 60\\% )$\n",
    "\n",
    "2. **Likelihood**:\n",
    "    - $( P(\\text{Positive} | \\text{Healthy}) = 0.1 )$\n",
    "    - $( P(\\text{Positive} | \\text{Infected}) = 0.95 )$\n",
    "\n",
    "3. **Evidence**:\n",
    "    - Total positive tests: $( 0.4 \\times 0.1 + 0.6 \\times 0.95 )$\n",
    "\n",
    "Using Bayes' formula:\n",
    "\n",
    "$[ P(\\text{Healthy} | \\text{Positive}) = \\frac{P(\\text{Positive} | \\text{Healthy}) \\times P(\\text{Healthy})}{P(\\text{Positive})} ]$\n",
    "\n",
    "$[ P(\\text{Healthy} | \\text{Positive}) = \\frac{0.1 \\times 0.4}{0.4 \\times 0.1 + 0.6 \\times 0.95} = \\frac{0.04}{0.04 + 0.57} = \\frac{0.04}{0.61} = \\frac{4}{61} ]$\n",
    "\n",
    "---\n",
    "\n",
    "## Project Description\n",
    "\n",
    "In this project, you are given a dataset in CSV format named `books_train.csv` containing book descriptions and their corresponding categories. Another file named `books_test.csv` contains descriptions of books without categories. Your task is to determine the category of each book based on its description.\n",
    "\n",
    "### Phase 1: Data Preprocessing\n",
    "\n",
    "The first phase involves preprocessing the text data. You can use the `hazm` library for this purpose. Manage the data files to ensure the best state for the project. Suggested preprocessing steps include removing punctuation, numbers, and formatting marks, as these do not provide specific information about the category of the books.\n",
    "\n",
    "### Phase 2: Problem Solving\n",
    "\n",
    "Using Bayes' Theorem and the concept of Bag of Words (BoW), solve the problem by determining the category of each book based on its description. \n",
    "\n",
    "#### Bag of Words Concept:\n",
    "\n",
    "Consider two sentences:\n",
    "\n",
    "1. \"I liked the food at this restaurant.\"\n",
    "2. \"The food at this restaurant was very good.\"\n",
    "\n",
    "Using BoW, these sentences can be represented as vectors of word occurrences.\n",
    "\n",
    "Assume the following words:\n",
    "\n",
    "$[\n",
    "\\text{food, restaurant, liked, good, very, I}\n",
    "]$\n",
    "\n",
    "Each sentence is then represented as:\n",
    "\n",
    "$[\n",
    "\\text{Sentence 1: [1, 1, 1, 0, 0, 1]}\n",
    "]$\n",
    "$[\n",
    "\\text{Sentence 2: [1, 1, 0, 1, 1, 0]}\n",
    "]$\n",
    "\n",
    "Using the BoW representation for the descriptions in `books_train.csv`, classify each book in `books_test.csv` using Bayes' Theorem.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Phases:\n",
    "\n",
    "#### Phase 3 (Optional, 40 points)\n",
    "\n",
    "1. **Part 1**: Consider the effect of stemming on the accuracy of predictions. Use the `hazm` library to stem words and compare results.\n",
    "\n",
    "2. **Part 2**: Investigate the impact of removing common words (e.g., stopwords) on the accuracy of predictions.\n",
    "\n",
    "3. **Part 3**: Combine the approaches from parts 1 and 2 and analyze the improvement in accuracy.\n",
    "\n",
    "4. **Part 4**: Draw confusion matrix using sns heatmap for final model.\n",
    "\n",
    "## KNN\n",
    "\n",
    "## Exercise 1:\n",
    "\n",
    "0. **Part 0**: Download `Metro_Interstate_Traffic_Volume dataset`.\n",
    "1. **Part 1**: Choose a feature from  temp,rain_1h,snow_1h and draw Box plot and histogram for it.\n",
    "2. **Part 2**: Choose a feature from clouds_all,weather_main,weather_description Draw  Bar Plot.\n",
    "3. **Part 3**: do preprocessing.\n",
    "4. **Part 4**: Use KNN to predict the Trafic volume.\n",
    "5. **Part 5**: Evaluate your model based on what you've learned.\n",
    "6. **Part 6**: Fine tune Your model.\n",
    "   \n",
    "## Excercise 2:\n",
    "One of the usages of KNN algorithm is in recommender systems.In this part,You develop a simple Recommender system using Surprise Library.\n",
    "\n",
    "0. **Part 0**: Download `ratings.csv`\n",
    "1. **Part 1**: in simple terms,explain what item-based collaborative filtering and user-based collabrative filtering is.\n",
    "2. **Part 2**: \"Cosine similarity\" is one of the metrics that we use for knn.What does this metric show?\n",
    "3. **Part 3**: Use surprise library and knn algorithm to develop a user based collaborative filtering model.(For preprocessing Part, do min-max scaling)\n",
    "4. **Part 4**: Print first five predictions and testset.\n",
    "   \n",
    "## SVM , logistic regression and ROC\n",
    "\n",
    "0. **Part 0**: Download `titanic.csv`.\n",
    "1. **Part 1**: Use titanic meta in the repository to understand what each feature shows.Then for each features choose one or two of the boxplot,histogram or barplot to draw.Draw scatter plot for each feature and target.Draw violon plot for age and compare it with normal distribution.\n",
    "2. **Part 2**: do preprocessing.\n",
    "3. **Part 3**: Use linear SVM to develop a model to predict which passengers  survive the titanic.\n",
    "4. **Part 4**: Use RBF SVM to develop a model to predict which passengers  survive the titanic.\n",
    "5. **Part 5**: Use logistic Regression to develop a model to predict which passengers  survive the titanic.\n",
    "6. **Part 6**: Draw ROC curve for models in part 3,4 and 5 and random guess.\n",
    "7. **Part 7**: Find the best model based on Part 6.\n",
    "8. **Part 8**: use AUC to find out whether your answer in Part 7 is true or not.\n",
    "9. **Part 9**: what is the best threshold for logistic regrssion?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099bcff-44f7-431b-8709-4078601664b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
